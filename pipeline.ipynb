{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6e991361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "val_df = pd.read_csv(\"./data/val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a0f37c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['loan_amnt', 'term', 'int_rate', 'installment', 'emp_length',\n",
       "       'annual_inc', 'dti', 'inq_last_6mths', 'delinq_2yrs', 'open_acc',\n",
       "       'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'loan_risk',\n",
       "       'installment_to_income', 'fico_score', 'credit_age', 'issue_month',\n",
       "       'fed_funds_rate', 'unemployment_rate', 'cpi', 'real_gdp',\n",
       "       'debt_service_ratio', 'car', 'credit_card', 'debt_consolidation',\n",
       "       'educational', 'home_improvement', 'house', 'major_purchase', 'medical',\n",
       "       'moving', 'other', 'renewable_energy', 'small_business', 'vacation',\n",
       "       'wedding', 'ANY', 'MORTGAGE', 'NONE', 'OTHER', 'OWN', 'RENT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "41e5d8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport matplotlib.pyplot as plt\\n\\nplt.hist(train_df['revol_util'], bins=50)\\nplt.title('Revolving Utilization Distribution')\\nplt.xlabel('Revol Util')\\nplt.ylabel('Frequency')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_df[\"int_rate\"].max() # 30.99\n",
    "#train_df[\"int_rate\"].min() # 5.31\n",
    "#train_df[\"emp_length\"].min() # -1\n",
    "#train_df[\"emp_length\"].max() # 10\n",
    "#train_df[\"dti\"].min() # -1\n",
    "#train_df[\"dti\"].max() # 999\n",
    "#train_df[\"inq_last_6mths\"].agg(['min', 'max'])\n",
    "#train_df[\"delinq_2yrs\"].agg(['min', 'max'])\n",
    "#train_df[\"open_acc\"].agg(['min', 'max'])\n",
    "#train_df[\"pub_rec\"].agg(['min', 'max'])\n",
    "#train_df[\"revol_bal\"].agg(['min', 'max'])\n",
    "#train_df[\"revol_util\"].agg(['min', 'max'])\n",
    "#train_df[\"total_acc\"].agg(['min', 'max'])\n",
    "#train_df[\"installment_to_income\"].agg(['min', 'max'])\n",
    "#train_df[\"fico_score\"].agg(['min', 'max'])\n",
    "#train_df[\"credit_age\"].agg(['min', 'max'])\n",
    "#train_df[\"fed_funds_rate\"].agg(['min', 'max'])\n",
    "#train_df[\"unemployment_rate\"].agg(['min', 'max'])\n",
    "#train_df[\"cpi\"].agg(['min', 'max'])\n",
    "#train_df[\"real_gdp\"].agg(['min', 'max'])\n",
    "#train_df[\"debt_service_ratio\"].agg(['min', 'max'])\n",
    "\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(train_df['revol_util'], bins=50)\n",
    "plt.title('Revolving Utilization Distribution')\n",
    "plt.xlabel('Revol Util')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fb34a5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df[\"loan_risk\"]\n",
    "X_train = train_df.drop(\"loan_risk\", axis=1)\n",
    "y_val = val_df[\"loan_risk\"]\n",
    "X_val = val_df.drop(\"loan_risk\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c62144e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataPolicy:\n",
    "    percent: Tuple[str, ...] = (\"int_rate\", \"fed_funds_rate\", \"unemployment_rate\", \"debt_service_ratio\", \"revol_util\") # 0 to 100\n",
    "    non_negative: Tuple[str, ...] = (\"loan_amnt\", \"installment\", \"annual_inc\", \"delinq_2yrs\", \"open_acc\", \"pub_rec\", \"revol_bal\", \"total_acc\", \"installment_to_income\", \"credit_age\") # Will be winsorized\n",
    "    skip: Tuple[str, ...] = (\"term\", \"loan_rism\", 'car', 'credit_card', 'debt_consolidation',\n",
    "       'educational', 'home_improvement', 'house', 'major_purchase', 'medical',\n",
    "       'moving', 'other', 'renewable_energy', 'small_business', 'vacation',\n",
    "       'wedding', 'ANY', 'MORTGAGE', 'NONE', 'OTHER', 'OWN', 'RENT', \"real_gdp\") # Doesnt do anything, safety\n",
    "\n",
    "    # Allowable ranges\n",
    "    bounds: Dict[str, Tuple[int, int]] = field(default_factory=lambda: {\n",
    "        \"emp_length\": (-1, 10),\n",
    "        \"dti\": (-1, 100),\n",
    "        \"inq_last_6mths\": (0, 10),\n",
    "        \"fico_score\": (350, 850),\n",
    "        \"cpi\": (100, 500)\n",
    "    })\n",
    "\n",
    "    upper_cap = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "af006a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from typing import Dict\n",
    "\n",
    "class DataTransform(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, policy: DataPolicy = DataPolicy()):\n",
    "        self.policy = policy\n",
    "        self.caps = {}\n",
    "\n",
    "    def binaryCol(self, c: pd.Series):\n",
    "        return set(pd.unique(c.dropna())) == {0, 1}\n",
    "        \n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        df = X.copy()\n",
    "        # Find cap for each column in non_negative policy\n",
    "        for col in self.policy.non_negative:\n",
    "            if col in df.columns and is_numeric_dtype(df[col]) and not self.binaryCol(df[col]):\n",
    "                self.caps[col] = float(df[col].quantile(self.policy.upper_cap))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame):\n",
    "        df = X.copy()\n",
    "\n",
    "        skip = set(self.policy.skip) # For safety\n",
    "        \n",
    "        for col in self.policy.percent:\n",
    "            if col in df.columns and col not in skip:\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"coerce\").clip(0, 100) # Limit to between 0, 100\n",
    "\n",
    "        for col in self.policy.non_negative:\n",
    "            if col in df.columns and col not in skip:\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"coerce\").clip(lower=0)\n",
    "                if col in self.caps:\n",
    "                    df[col] = pd.to_numeric(df[col], errors=\"coerce\").clip(upper=self.caps[col])\n",
    "\n",
    "        # Bounds\n",
    "        bounds = self.policy.bounds\n",
    "        for col in bounds:\n",
    "            if col in df.columns and col not in skip:\n",
    "                df[col] = pd.to_numeric(df[col], errors=\"coerce\").clip(bounds[col][0], bounds[col][1])\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a4c8787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM (CPU)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgbm_model = Pipeline([\n",
    "    (\"transform\", DataTransform()),\n",
    "    (\"clf\", lgb.LGBMClassifier(\n",
    "        n_estimators=4000, learning_rate=0.02,\n",
    "        num_leaves=31, subsample=0.8,\n",
    "        min_child_samples=100, reg_alpha=1.0, reg_lambda=1.0,\n",
    "        colsample_bytree=0.8, objective=\"binary\", \n",
    "        is_unbalance=True, random_state=42\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "77d3b59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 199033, number of negative: 1380977\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2401\n",
      "[LightGBM] [Info] Number of data points in the train set: 1580010, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.125969 -> initscore=-1.937076\n",
      "[LightGBM] [Info] Start training from score -1.937076\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's average_precision: 0.252527\tvalid_0's binary_logloss: 0.517476\n",
      "[100]\tvalid_0's average_precision: 0.25502\tvalid_0's binary_logloss: 0.623692\n",
      "[150]\tvalid_0's average_precision: 0.256999\tvalid_0's binary_logloss: 0.667496\n",
      "[200]\tvalid_0's average_precision: 0.258864\tvalid_0's binary_logloss: 0.680724\n",
      "[250]\tvalid_0's average_precision: 0.260199\tvalid_0's binary_logloss: 0.682456\n",
      "[300]\tvalid_0's average_precision: 0.261176\tvalid_0's binary_logloss: 0.681613\n",
      "[350]\tvalid_0's average_precision: 0.262245\tvalid_0's binary_logloss: 0.679354\n",
      "[400]\tvalid_0's average_precision: 0.262871\tvalid_0's binary_logloss: 0.677351\n",
      "[450]\tvalid_0's average_precision: 0.263167\tvalid_0's binary_logloss: 0.675985\n",
      "[500]\tvalid_0's average_precision: 0.26326\tvalid_0's binary_logloss: 0.675069\n",
      "[550]\tvalid_0's average_precision: 0.263387\tvalid_0's binary_logloss: 0.67417\n",
      "[600]\tvalid_0's average_precision: 0.263434\tvalid_0's binary_logloss: 0.673841\n",
      "[650]\tvalid_0's average_precision: 0.263568\tvalid_0's binary_logloss: 0.67337\n",
      "[700]\tvalid_0's average_precision: 0.263686\tvalid_0's binary_logloss: 0.672812\n",
      "[750]\tvalid_0's average_precision: 0.263785\tvalid_0's binary_logloss: 0.67228\n",
      "[800]\tvalid_0's average_precision: 0.263851\tvalid_0's binary_logloss: 0.671863\n",
      "[850]\tvalid_0's average_precision: 0.263929\tvalid_0's binary_logloss: 0.671705\n",
      "[900]\tvalid_0's average_precision: 0.264023\tvalid_0's binary_logloss: 0.671136\n",
      "[950]\tvalid_0's average_precision: 0.264099\tvalid_0's binary_logloss: 0.67088\n",
      "[1000]\tvalid_0's average_precision: 0.264161\tvalid_0's binary_logloss: 0.670601\n",
      "[1050]\tvalid_0's average_precision: 0.264191\tvalid_0's binary_logloss: 0.670319\n",
      "[1100]\tvalid_0's average_precision: 0.264235\tvalid_0's binary_logloss: 0.670013\n",
      "[1150]\tvalid_0's average_precision: 0.264275\tvalid_0's binary_logloss: 0.66971\n",
      "[1200]\tvalid_0's average_precision: 0.264315\tvalid_0's binary_logloss: 0.669268\n",
      "[1250]\tvalid_0's average_precision: 0.264382\tvalid_0's binary_logloss: 0.668965\n",
      "[1300]\tvalid_0's average_precision: 0.26446\tvalid_0's binary_logloss: 0.668759\n",
      "[1350]\tvalid_0's average_precision: 0.264536\tvalid_0's binary_logloss: 0.668322\n",
      "[1400]\tvalid_0's average_precision: 0.264561\tvalid_0's binary_logloss: 0.668063\n",
      "[1450]\tvalid_0's average_precision: 0.264603\tvalid_0's binary_logloss: 0.668013\n",
      "[1500]\tvalid_0's average_precision: 0.264687\tvalid_0's binary_logloss: 0.667513\n",
      "[1550]\tvalid_0's average_precision: 0.264743\tvalid_0's binary_logloss: 0.667096\n",
      "[1600]\tvalid_0's average_precision: 0.264787\tvalid_0's binary_logloss: 0.66687\n",
      "[1650]\tvalid_0's average_precision: 0.264821\tvalid_0's binary_logloss: 0.666623\n",
      "[1700]\tvalid_0's average_precision: 0.264884\tvalid_0's binary_logloss: 0.666281\n",
      "[1750]\tvalid_0's average_precision: 0.264937\tvalid_0's binary_logloss: 0.666126\n",
      "[1800]\tvalid_0's average_precision: 0.264987\tvalid_0's binary_logloss: 0.665993\n",
      "[1850]\tvalid_0's average_precision: 0.265\tvalid_0's binary_logloss: 0.665539\n",
      "[1900]\tvalid_0's average_precision: 0.265021\tvalid_0's binary_logloss: 0.665034\n",
      "[1950]\tvalid_0's average_precision: 0.265072\tvalid_0's binary_logloss: 0.664904\n",
      "[2000]\tvalid_0's average_precision: 0.265118\tvalid_0's binary_logloss: 0.664546\n",
      "[2050]\tvalid_0's average_precision: 0.265154\tvalid_0's binary_logloss: 0.664486\n",
      "[2100]\tvalid_0's average_precision: 0.265185\tvalid_0's binary_logloss: 0.664187\n",
      "[2150]\tvalid_0's average_precision: 0.265225\tvalid_0's binary_logloss: 0.663759\n",
      "[2200]\tvalid_0's average_precision: 0.265273\tvalid_0's binary_logloss: 0.663487\n",
      "[2250]\tvalid_0's average_precision: 0.265309\tvalid_0's binary_logloss: 0.663256\n",
      "[2300]\tvalid_0's average_precision: 0.265343\tvalid_0's binary_logloss: 0.66303\n",
      "[2350]\tvalid_0's average_precision: 0.265348\tvalid_0's binary_logloss: 0.662757\n",
      "[2400]\tvalid_0's average_precision: 0.26536\tvalid_0's binary_logloss: 0.662572\n",
      "[2450]\tvalid_0's average_precision: 0.265414\tvalid_0's binary_logloss: 0.662233\n",
      "[2500]\tvalid_0's average_precision: 0.265439\tvalid_0's binary_logloss: 0.66197\n",
      "[2550]\tvalid_0's average_precision: 0.265475\tvalid_0's binary_logloss: 0.661641\n",
      "[2600]\tvalid_0's average_precision: 0.265509\tvalid_0's binary_logloss: 0.661294\n",
      "[2650]\tvalid_0's average_precision: 0.265548\tvalid_0's binary_logloss: 0.661168\n",
      "[2700]\tvalid_0's average_precision: 0.265581\tvalid_0's binary_logloss: 0.660897\n",
      "[2750]\tvalid_0's average_precision: 0.265618\tvalid_0's binary_logloss: 0.660664\n",
      "[2800]\tvalid_0's average_precision: 0.265634\tvalid_0's binary_logloss: 0.660496\n",
      "[2850]\tvalid_0's average_precision: 0.265694\tvalid_0's binary_logloss: 0.66031\n",
      "[2900]\tvalid_0's average_precision: 0.26574\tvalid_0's binary_logloss: 0.660075\n",
      "[2950]\tvalid_0's average_precision: 0.26576\tvalid_0's binary_logloss: 0.659906\n",
      "[3000]\tvalid_0's average_precision: 0.265761\tvalid_0's binary_logloss: 0.659665\n",
      "[3050]\tvalid_0's average_precision: 0.265764\tvalid_0's binary_logloss: 0.659323\n",
      "[3100]\tvalid_0's average_precision: 0.265786\tvalid_0's binary_logloss: 0.659207\n",
      "[3150]\tvalid_0's average_precision: 0.265824\tvalid_0's binary_logloss: 0.659058\n",
      "[3200]\tvalid_0's average_precision: 0.265835\tvalid_0's binary_logloss: 0.658811\n",
      "[3250]\tvalid_0's average_precision: 0.265844\tvalid_0's binary_logloss: 0.658616\n",
      "[3300]\tvalid_0's average_precision: 0.265867\tvalid_0's binary_logloss: 0.65844\n",
      "[3350]\tvalid_0's average_precision: 0.265883\tvalid_0's binary_logloss: 0.65822\n",
      "[3400]\tvalid_0's average_precision: 0.265871\tvalid_0's binary_logloss: 0.657991\n",
      "[3450]\tvalid_0's average_precision: 0.265902\tvalid_0's binary_logloss: 0.657864\n",
      "[3500]\tvalid_0's average_precision: 0.265907\tvalid_0's binary_logloss: 0.657651\n",
      "[3550]\tvalid_0's average_precision: 0.265903\tvalid_0's binary_logloss: 0.657545\n",
      "[3600]\tvalid_0's average_precision: 0.265917\tvalid_0's binary_logloss: 0.657273\n",
      "[3650]\tvalid_0's average_precision: 0.265925\tvalid_0's binary_logloss: 0.65697\n",
      "[3700]\tvalid_0's average_precision: 0.265995\tvalid_0's binary_logloss: 0.656882\n",
      "[3750]\tvalid_0's average_precision: 0.266051\tvalid_0's binary_logloss: 0.656512\n",
      "[3800]\tvalid_0's average_precision: 0.266059\tvalid_0's binary_logloss: 0.656317\n",
      "[3850]\tvalid_0's average_precision: 0.266083\tvalid_0's binary_logloss: 0.656143\n",
      "[3900]\tvalid_0's average_precision: 0.26611\tvalid_0's binary_logloss: 0.655997\n",
      "[3950]\tvalid_0's average_precision: 0.266099\tvalid_0's binary_logloss: 0.655778\n",
      "[4000]\tvalid_0's average_precision: 0.266139\tvalid_0's binary_logloss: 0.655471\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\tvalid_0's average_precision: 0.266139\tvalid_0's binary_logloss: 0.655471\n",
      "Evaluated only: average_precision\n",
      "Done training.\n",
      "Finished predicitons.\n",
      "Avg prec. score: 0.26613946935423727\n",
      "ROC AUC Score: 0.6992717675554609\n"
     ]
    }
   ],
   "source": [
    "lgbm_model.fit(\n",
    "    X_train, y_train,\n",
    "    clf__eval_set=[(X_val, y_val)],\n",
    "    clf__eval_metric=\"average_precision\",\n",
    "    clf__callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=200, first_metric_only=True),\n",
    "        lgb.log_evaluation(period=50)\n",
    "    ]\n",
    ")\n",
    "print(\"Done training.\")\n",
    "val_pred = lgbm_model.predict_proba(X_val)[:, 1]\n",
    "print(\"Finished predicitons.\")\n",
    "print(f\"Avg prec. score: {average_precision_score(y_val, val_pred)}\\nROC AUC Score: {roc_auc_score(y_val, val_pred)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0a9c45f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Brier: 0.11149527235774853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "# Calibrate\n",
    "cal = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "cal.fit(val_pred, y_val.astype(int))\n",
    "\n",
    "val_pd = cal.predict(val_pred)\n",
    "print(\"Val Brier:\", brier_score_loss(y_val, val_pd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d2fc695a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg prec. score: 0.26302077987063066\n",
      "ROC AUC Score: 0.6996964334222409\n"
     ]
    }
   ],
   "source": [
    "print(f\"Avg prec. score: {average_precision_score(y_val, val_pd)}\\nROC AUC Score: {roc_auc_score(y_val, val_pd)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15597f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost (GPU)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loan-risk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
